{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return {item['cuisine_id']: item for item in json.load(f)}\n",
    "\n",
    "gt_file = 'ground_truth.json'\n",
    "gpt_file = 'response_gpt.json'\n",
    "gemini_file = 'response_gemini.json'\n",
    "claude_file = 'response_claude.json'\n",
    "\n",
    "gt_data = load_json(gt_file)\n",
    "gpt_data = load_json(gpt_file)\n",
    "gemini_data = load_json(gemini_file)\n",
    "claude_data = load_json(claude_file)\n",
    "\n",
    "print(gt_data)\n",
    "print(gpt_data)\n",
    "print(gemini_data)\n",
    "print(claude_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c50aa",
   "metadata": {},
   "source": [
    "## 資料整理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ca854",
   "metadata": {},
   "source": [
    "### ingredients 變成 sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {id:\" \", ing:\" \"}\n",
    "gt_ing_sentence_dic = {}\n",
    "gpt_ing_sentence_dic = {}\n",
    "gemini_ing_sentence_dic = {}\n",
    "claude_ing_sentence_dic = {}\n",
    "\n",
    "def ingredients_to_sentence (data):\n",
    "    ing_sentence = {}\n",
    "    for item in data:\n",
    "        sentence = \"\"\n",
    "        for ingredient_list in data[item]['ingredients']:\n",
    "            sentence = sentence + ingredient_list['ingredient'] + \" \"\n",
    "        ing_sentence[item] = sentence\n",
    "    return ing_sentence\n",
    "\n",
    "gt_ing_sentence_dic = ingredients_to_sentence(gt_data)\n",
    "gpt_ing_sentence_dic = ingredients_to_sentence(gpt_data)\n",
    "gemini_ing_sentence_dic = ingredients_to_sentence(gemini_data)\n",
    "claude_ing_sentence_dic = ingredients_to_sentence(claude_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b57c1",
   "metadata": {},
   "source": [
    "### Instruction 變成 sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84cc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {id:\" \", instrc:\" \"}\n",
    "gt_instrc_sentence_dic = {}\n",
    "gpt_instrc_sentence_dic = {}\n",
    "gemini_instrc_sentence_dic = {}\n",
    "claude_instrc_sentence_dic = {}\n",
    "\n",
    "def instructions_to_sentence (data):\n",
    "    print(data)\n",
    "    instrc_sentence = {}\n",
    "    for item in data:\n",
    "        print(data[item]['cooking_instructions'])\n",
    "        instrc_sentence[item] = data[item]['cooking_instructions']\n",
    "    return instrc_sentence\n",
    "\n",
    "gt_instrc_sentence_dic = instructions_to_sentence(gt_data)\n",
    "gpt_instrc_sentence_dic = instructions_to_sentence(gpt_data)\n",
    "gemini_instrc_sentence_dic = instructions_to_sentence(gemini_data)\n",
    "claude_instrc_sentence_dic = instructions_to_sentence(claude_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082ebb8",
   "metadata": {},
   "source": [
    "## 食材種類正確性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716fe946",
   "metadata": {},
   "source": [
    "### bert_base_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5bc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e9fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_ing_bert_base_chinese = []\n",
    "gemini_ing_bert_base_chinese = []\n",
    "claude_ing_bert_base_chinese = []\n",
    "\n",
    "def bert_base_chinese_for_ing_sentence(gt_ing_sentence, model_ing_sentence):\n",
    "    print(gt_ing_sentence)\n",
    "    print(model_ing_sentence)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "    model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "    inputs = tokenizer(gt_ing_sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    gt_embedding = outputs.last_hidden_state[:, 0, :]  # shape: [1, hidden_size]\n",
    "\n",
    "    inputs = tokenizer(model_ing_sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    model_embedding = outputs.last_hidden_state[:, 0, :]  # shape: [1, hidden_size]\n",
    "        \n",
    "    # 計算餘弦相似度（值域 -1 到 1，越接近 1 越相似）\n",
    "    similarity = F.cosine_similarity(gt_embedding, model_embedding)\n",
    "    print(f\"相似度: {similarity.item():.4f}\")\n",
    "    return similarity.item()\n",
    "\n",
    "def get_ing_bert_base_chinese(gt_ing_sentence_dic, model_ing_sentence_dic):\n",
    "    ing_bert_base_chinese = []\n",
    "    for gt_id, model_id in zip(gt_ing_sentence_dic, model_ing_sentence_dic):\n",
    "        sentence1 = gt_ing_sentence_dic[gt_id]\n",
    "        sentence2 = model_ing_sentence_dic[model_id]\n",
    "        print(sentence1)\n",
    "        print(sentence2)\n",
    "        ing_bert_base_chinese.append(bert_base_chinese_for_ing_sentence(sentence1, sentence2))\n",
    "    return ing_bert_base_chinese\n",
    "\n",
    "gpt_ing_bert_base_chinese = get_ing_bert_base_chinese(gt_ing_sentence_dic, gpt_ing_sentence_dic)\n",
    "gemini_ing_bert_base_chinese = get_ing_bert_base_chinese(gt_ing_sentence_dic, gemini_ing_sentence_dic)\n",
    "claude_ing_bert_base_chinese = get_ing_bert_base_chinese(gt_ing_sentence_dic, claude_ing_sentence_dic)\n",
    "\n",
    "print(f'gpt_ing_bert_base_chinese = {gpt_ing_bert_base_chinese}')\n",
    "print(f'gemini_ing_bert_base_chinese = {gemini_ing_bert_base_chinese}')\n",
    "print(f'claude_ing_bert_base_chinese = {claude_ing_bert_base_chinese}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a84f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = list(range(1, 16))\n",
    "x2 = [i + 0.2 for i in x]\n",
    "x3 = [i - 0.2 for i in x]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color_map = {0: \"#e9f1c3\", 5: \"#c4edfb\", 10: \"#f7dfcb\"}\n",
    "\n",
    "for i in range(0, 15, 5):\n",
    "    ax.axvspan(i + 0.5, i + 5.5, facecolor=color_map[i], alpha=0.99)\n",
    "\n",
    "# 畫長條圖\n",
    "ax.bar(x3, claude_ing_bert_base_chinese, color='g', width=0.2, label='Claude')\n",
    "ax.bar(x, gemini_ing_bert_base_chinese, color='r', width=0.2, label='Gemini')\n",
    "ax.bar(x2, gpt_ing_bert_base_chinese, color='b', width=0.2, label='GPT')\n",
    "\n",
    "# 加上 legend、標題與格式調整\n",
    "ax.legend()\n",
    "ax.set_xticks(range(1, 16))\n",
    "ax.set_xlabel('Samples', fontsize=12)\n",
    "ax.set_ylabel('Bert', fontsize=12)\n",
    "ax.set_title('Ingredients bert', fontsize=14)\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ing_bert.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08769636",
   "metadata": {},
   "source": [
    "## Cooking Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_instrc_bert_base_chinese = []\n",
    "gemini_instrc_bert_base_chinese = []\n",
    "claude_instrc_bert_base_chinese = []\n",
    "\n",
    "def bert_base_chinese_for_instrc_sentence(gt_instrc_sentence, model_instrc_sentence):\n",
    "    print(gt_instrc_sentence)\n",
    "    print(model_instrc_sentence)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "    model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "    inputs = tokenizer(gt_instrc_sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    gt_embeddinstrc = outputs.last_hidden_state[:, 0, :]  # shape: [1, hidden_size]\n",
    "\n",
    "    inputs = tokenizer(model_instrc_sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    model_embeddinstrc = outputs.last_hidden_state[:, 0, :]  # shape: [1, hidden_size]\n",
    "        \n",
    "    # 計算餘弦相似度（值域 -1 到 1，越接近 1 越相似）\n",
    "    similarity = F.cosine_similarity(gt_embeddinstrc, model_embeddinstrc)\n",
    "    print(f\"相似度: {similarity.item():.4f}\")\n",
    "    return similarity.item()\n",
    "\n",
    "def get_instrc_bert_base_chinese(gt_instrc_sentence_dic, model_instrc_sentence_dic):\n",
    "    instrc_bert_base_chinese = []\n",
    "    for gt_id, model_id in zip(gt_instrc_sentence_dic, model_instrc_sentence_dic):\n",
    "        sentence1 = gt_instrc_sentence_dic[gt_id]\n",
    "        sentence2 = model_instrc_sentence_dic[model_id]\n",
    "        print(sentence1)\n",
    "        print(sentence2)\n",
    "        instrc_bert_base_chinese.append(bert_base_chinese_for_instrc_sentence(sentence1, sentence2))\n",
    "    return instrc_bert_base_chinese\n",
    "\n",
    "gpt_instrc_bert_base_chinese = get_instrc_bert_base_chinese(gt_instrc_sentence_dic, gpt_instrc_sentence_dic)\n",
    "gemini_instrc_bert_base_chinese = get_instrc_bert_base_chinese(gt_instrc_sentence_dic, gemini_instrc_sentence_dic)\n",
    "claude_instrc_bert_base_chinese = get_instrc_bert_base_chinese(gt_instrc_sentence_dic, claude_instrc_sentence_dic)\n",
    "\n",
    "print(f'gpt_instrc_bert_base_chinese = {gpt_instrc_bert_base_chinese}')\n",
    "print(f'gemini_instrc_bert_base_chinese = {gemini_instrc_bert_base_chinese}')\n",
    "print(f'claude_instrc_bert_base_chinese = {claude_instrc_bert_base_chinese}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, 16))\n",
    "x2 = [i + 0.2 for i in x]\n",
    "x3 = [i - 0.2 for i in x]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color_map = {0: \"#e9f1c3\", 5: \"#c4edfb\", 10: \"#f7dfcb\"}\n",
    "\n",
    "for i in range(0, 15, 5):\n",
    "    ax.axvspan(i + 0.5, i + 5.5, facecolor=color_map[i], alpha=0.99)\n",
    "\n",
    "# 畫長條圖\n",
    "ax.bar(x3, claude_instrc_bert_base_chinese, color='g', width=0.2, label='Claude')\n",
    "ax.bar(x, gemini_instrc_bert_base_chinese, color='r', width=0.2, label='Gemini')\n",
    "ax.bar(x2, gpt_instrc_bert_base_chinese, color='b', width=0.2, label='GPT')\n",
    "\n",
    "# 加上 legend、標題與格式調整\n",
    "ax.legend()\n",
    "ax.set_xticks(range(1, 16))\n",
    "ax.set_xlabel('Samples', fontsize=12)\n",
    "ax.set_ylabel('Bert', fontsize=12)\n",
    "ax.set_title('Cooking Instructions bert', fontsize=14)\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('instrc_bert.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

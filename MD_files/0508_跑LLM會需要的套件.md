在跑模型的時候，會需要pip install一些套件，如果使用的是peotry，也可以用poetry add來裝。

## 常常看到的新套件
### gradio 
功能 : 可以生出一個漂亮的網頁介面
試著跑跑看這段程式碼，會有意想不到的結果，這也太先進了吧
```python=
import gradio as gr

def greet(name, is_morning, temperature):
    salutation = "Good morning" if is_morning else "Good evening"
    greeting = f"{salutation} {name}. It is {temperature} degrees today"
    celsius = (temperature - 32) * 5 / 9
    return greeting, round(celsius, 2)

demo = gr.Interface(
    fn=greet,
    inputs=["text", "checkbox", gr.Slider(0, 100)],
    outputs=["text", "number"],
)
if __name__ == "__main__":
    demo.launch()
```

### peft
Parameter-Efficient Fine-Tuning
可以參考下面這篇文章，講的蠻清楚的，目前先學peft的兩種方法，prompt tuning和LoRA，前者是克漏字，後者是加上low rank的權重截距。

[什麼是效率微調](https://ywctech.net/ml-ai/quick-intro-to-peft/)
:::info
Calorify那篇就有用到peft這個套件，那個時候還不知道這是什麼，但現在回來看覺得那是為了lora而裝的)
:::

### evaluate
這也是一個hugging face的library，可以用來評估模型的表現，裡面有許多常見的metrics
:::info
Calorify 也有import到這個函式庫，但那時候我不知道這是函式庫，以為是消失的檔案，就把他註解掉了...
:::

## 補充說明
通常網路上包好的project都會有一個檔案叫做"requirement.txt"，裡面會提到需要哪些libraries.
[點進去這個github_介紹fine-tuning](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning)


## 題外話
### Ollama
Ollama 是一個開源的本地大型語言模型（LLM）運行框架，支援多種開源的大型語言模型，如 Llama 3、Phi 3、Mistral、Gemma。
1. curl -fsSL https://ollama.com/install.sh | sh(下載ollama)
2. ollama serve(啟用)
3. ollama download gemma:2b(下載gemma:2b模型)
4. ollama run gemma:2b(運行模型)
之後的介面應該會像是GPT一樣的

:::info
0507有在colab上面跑過，就真的是GPT的感覺...
:::
